{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 Intro\n",
    "This script will scrape the songs data from genius, then save it to DATASET_PATH location, cutting out rappers which don't have more than POPULARITY_OFFSET songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Global imports, setting variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GENIUS_LINK = \"http://genius.com\"\n",
    "API_LINK = \"http://api.genius.com/\"\n",
    "client_access_token = \"vJuRYtZOmqJwepQq0mAH5fqaxO3Yw9hM0b9wzguKf40yLii05QLVjTwC4o50XH4G\"\n",
    "DATASET_PATH = \"/home/jack/datasets/polish_rap/\"\n",
    "POPULARITY_OFFSET = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Pre-crawling\n",
    "Rapper names from hot16 challenge list, then rappers ids to use in genius api, then songs links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_songs(artist_id):\n",
    "    try_on = True #checks if there are still some songs left\n",
    "    artist_id = str(artist_id)\n",
    "    pagination = 0\n",
    "    paths = []\n",
    "    while try_on:\n",
    "        try_on = False\n",
    "        pagination += 1\n",
    "        rq = urllib.request.Request(\"http://api.genius.com/artists/\" + artist_id + \\\n",
    "                                    \"/songs?per_page=50&page=\" + str(pagination))\n",
    "        rq.add_header(\"Authorization\", \"Bearer \" + client_access_token)\n",
    "        rq.add_header(\"User-Agent\", \\\n",
    "                      \"curl/7.9.8 (i686-pc-linux-gnu) libcurl 7.9.8 (OpenSSL 0.9.6b) (ipv6 enabled)\")\n",
    "        try:\n",
    "            resp = urllib.request.urlopen(rq)\n",
    "            r = json.loads(resp.read().decode(\"utf-8\"))\n",
    "        except:\n",
    "            print(\"Rapper is not in database: \" + artist_id)\n",
    "            return []\n",
    "        for k in r[\"response\"][\"songs\"]:\n",
    "            paths.append(k[\"path\"])\n",
    "            try_on = True\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_song_text(song_path):\n",
    "    data = requests.get(GENIUS_LINK+song_path).text\n",
    "    \n",
    "    soup = bs(data, \"lxml\")\n",
    "    for div in soup.findAll(\"lyrics\", attrs={\"class\":\"lyrics\"}):\n",
    "        return div.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_artist_id(artist_name):\n",
    "    data = requests.get(GENIUS_LINK+\"/artists/\"+artist_name).text\n",
    "    \n",
    "    soup = bs(data, \"lxml\")\n",
    "    for a in soup.findAll(attrs={\"name\": \"newrelic-resource-path\"}):\n",
    "        return a.attrs[\"content\"].split(\"/\")[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_all_songs(names, force=False):\n",
    "    all_songs_path = DATASET_PATH + \"songs_by_artist.json\"\n",
    "    rappers_ids_path = DATASET_PATH + \"rappers_ids.json\"\n",
    "    if os.path.exists(all_songs_path) and not force:\n",
    "        with open(all_songs_path, \"r\") as f:\n",
    "            all_songs = json.load(f)\n",
    "        with open(rappers_ids_path, \"r\") as f:\n",
    "            rappers_ids = json.load(f)\n",
    "    else:\n",
    "        all_songs = {}\n",
    "        rappers_ids = {}\n",
    "        for rapper_name in tqdm(names):\n",
    "            rapper_id = get_artist_id(rapper_name)\n",
    "            rappers_ids[rapper_name] = rapper_id\n",
    "#             songs = get_songs(rapper_id)\n",
    "            songs = None\n",
    "            all_songs[rapper_name] = songs\n",
    "        \n",
    "        if not os.path.exists(DATASET_PATH):\n",
    "            os.makedirs(DATASET_PATH)\n",
    "        with open(all_songs_path, \"w\") as f:\n",
    "            json.dump(all_songs, f, ensure_ascii=False)\n",
    "        with open(rappers_ids_path, \"w\") as f:\n",
    "            json.dump(rappers_ids, f, ensure_ascii=False)\n",
    "    \n",
    "    return all_songs, rappers_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_polish_rappers_names():\n",
    "    href = \"/Rap-genius-polska-lista-raperow-ktorzy-ukonczyli-hot-16-challenge-lyrics\"\n",
    "    polish_list = get_song_text(href)\n",
    "    polish_list = polish_list.split(\"\\n\")\n",
    "    polish_list = list(filter(lambda rp: 15 > len(rp) > 3, polish_list))\n",
    "    polish_list = list(map(lambda rp: re.sub(\" \", \"-\", rp), polish_list))\n",
    "    return polish_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "polish_list = get_polish_rappers_names()\n",
    "polish_list = [s.replace(\".\", \"\") for s in polish_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def clean_text(s):\n",
    "    s = re.sub(r'\\[.*\\]', '', s)\n",
    "    s = re.sub(r'[\\n]+', '\\n', s)\n",
    "    return s[s.find('Lyrics')+len(\"Lyrics \"):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|â–‹         | 27/374 [00:24<05:05,  1.14it/s]"
     ]
    }
   ],
   "source": [
    "all_songs, rappers_ids = get_all_songs(polish_list, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def clean_songs(songs_dict):\n",
    "    res = defaultdict(list)\n",
    "    for rapper, songs in songs_dict.items():\n",
    "        for song in songs:\n",
    "            if \"/\" + rapper in song:\n",
    "                res[rapper].append(song)\n",
    "    return dict(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_songs = clean_songs(all_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Cleaning list of rappers\n",
    "Removing non-polish, rappers with empty songs list etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "empty_rappers = list(filter(lambda k: k not in all_songs or not all_songs[k], polish_list))\n",
    "non_polish_rappers = [\"Eminem\", \"Bonez\", \"Derk\", \"Kidman\", \"Kord\", \\\n",
    "                      \"Kordas\", \"Made\", \"Maestro\", \"Mikey-Kim\", \"Mona\", \"Oldas\", \"Perry\", \"Peti\", \"Shin\", \"Tazz\", \"Mikey\"]\n",
    "non_rappers = list(filter(lambda k: \"DJ\" in k, polish_list))\n",
    "non_rappers.append(\"Dj\")\n",
    "non_rappers.append(\"Antologia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_polish_rappers = set(polish_list)\n",
    "not_good_rappers = set()\n",
    "not_good_rappers |= set(empty_rappers)\n",
    "not_good_rappers |= set(non_polish_rappers)\n",
    "not_good_rappers |= set(non_rappers)\n",
    "good_polish_rappers -= not_good_rappers\n",
    "\n",
    "good_polish_rappers.add(\"Mickiewicz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(good_polish_rappers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.3 Crawling songs\n",
    "Web scraping from genius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dump_songs(rapper_name, force=False):\n",
    "    rapper_path = DATASET_PATH + \"all_lyrics/\" + rapper_name\n",
    "    if not os.path.exists(rapper_path) or force: \n",
    "        os.makedirs(rapper_path)\n",
    "        try:\n",
    "            for song in all_songs[rapper_name]:\n",
    "                lyrics = get_song_text(song)\n",
    "                song = song.split(\"/\")[1]\n",
    "                lyrics_plus_meta = {}\n",
    "                lyrics_plus_meta[\"lyrics\"] = clean_text(lyrics)\n",
    "                with open(rapper_path + \"/\" + song, \"w\") as f:\n",
    "                    json.dump(lyrics_plus_meta, f, ensure_ascii=False)\n",
    "        except:\n",
    "            print(\"There was a problem with rapper:\" + rapper_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dump_all_lyrics(rappers_names):\n",
    "    for rapper in tqdm(rappers_names):\n",
    "        dump_songs(rapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dump_all_lyrics(good_polish_rappers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.4 Cleaning data\n",
    "detecting language, moving songs to their's main artists dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def optionally_create(artist_name):\n",
    "    if not os.path.exists(DATASET_PATH + \"ok_lyrics/\" + artist_name):\n",
    "        os.mkdir(DATASET_PATH + \"ok_lyrics/\" + artist_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_data():\n",
    "    #clean rappers names and languages\n",
    "    optionally_create(\"\")\n",
    "    rappers = os.listdir(DATASET_PATH + \"all_lyrics/\")\n",
    "    for rapper in tqdm(rappers):\n",
    "        if not os.path.exists(DATASET_PATH + \"ok_lyrics/\" + rapper): #hack for mickiewicz, comment it\n",
    "            files = os.listdir(DATASET_PATH + \"all_lyrics/\" + rapper)\n",
    "            for song in files:\n",
    "                song_path = DATASET_PATH + \"all_lyrics/\" + rapper + \"/\" + song\n",
    "                with open(song_path, \"r\") as f:\n",
    "                    song_text = json.load(f)[\"lyrics\"]\n",
    "                try:\n",
    "                    lang = detect(song_text)\n",
    "                except:\n",
    "                    lang = \"xx\"\n",
    "                if lang != \"pl\" :\n",
    "                    #optionally delete them, but for now just leave\n",
    "                    #os.remove(song_path)\n",
    "                    pass\n",
    "                else:\n",
    "                    #clean every dir - move songs that doesnt start with the name of a rapper \n",
    "                    #to a new dir and add rapper to list\n",
    "                    main_artist = song.split(\"-\")[0]\n",
    "                    optionally_create(main_artist)\n",
    "                    os.rename(song_path, DATASET_PATH + \"ok_lyrics/\" + main_artist + \"/\" + song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clean_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.5 Selecting popular rappers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cut_out_popular(offset=POPULARITY_OFFSET):\n",
    "    popularity = {}\n",
    "    rappers = os.listdir(DATASET_PATH + \"ok_lyrics/\")\n",
    "    for rapper in tqdm(rappers):\n",
    "        files = os.listdir(DATASET_PATH + \"ok_lyrics/\" + rapper)\n",
    "        l = list(filter(lambda r: r.startswith(rapper+\"-\"), good_polish_rappers))\n",
    "        if l:\n",
    "            os.rename(DATASET_PATH + \"ok_lyrics/\" + rapper, DATASET_PATH + \"ok_lyrics/\" + l[0])\n",
    "            rapper = l[0]\n",
    "        if ((len(files) < offset) or (rapper in not_good_rappers)) and rapper != \"Mickiewicz\":\n",
    "            shutil.rmtree(DATASET_PATH + \"ok_lyrics/\" + rapper)\n",
    "        else:\n",
    "            popularity[rapper] = len(files)\n",
    "    return popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"Mickiewicz\" in good_polish_rappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popularity = cut_out_popular()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.6 Exploring popular rappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOP_N = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "popularity_df = pd.DataFrame.from_dict(popularity, \"index\")\n",
    "popularity_df.columns = [\"popularity\"]\n",
    "popularity_df.sort_values(by=\"popularity\", inplace=True, ascending=False)\n",
    "# print(popularity_df)\n",
    "popularity_df[:TOP_N].plot(kind=\"barh\", figsize=(15,15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"There were \" + str(len(popularity)) + \" popular rappers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
